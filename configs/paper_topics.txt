 1. New methodological improvements to RLHF or instruction-following which are specific fine-tuning steps that are taken to make language models better at following user instructions across a range of tasks.
    - Relevant: papers that discuss specific methods like RLHF, or instruction-tuning datasets, improving these methods, or analyzing them. Usually these papers will explicitly mention RLHF, instruction-following or instruction-tuning.
    - Not relevant: papers about adaptation to some task. Simply following instructions or inputs are not sufficient.
 2. Describes new paradigms to evaluating open-ended text generation. Evaluating the outputs of language models is hard, especially in open-ended settings like for chatbots.
    - Relevant: papers that fundamentally rethink language model evaluation -- especially by accounting for subjectivity or using adversaries.
    - Not relevant: specific evaluations for specific tasks, identifying new properties or flaws of language models, or simply collecting new data.
 3. New methodological improvements of current large language models which are mainly focus on the efficiency improvement.
    - Relevant: papers that discuss long context processing tasks, propose new algorithms to improve the inference of training efficiency.
    - Not relevant: papers that simply apply current methods on new applications.
 4. Studies 'scaling laws' in the context of neural networks. Scaling laws refer to the very clear power-law relationship between the size or computational power used to train a model and the performance of that model.
    - Relevant: theoretical or conceptual explanation behind scaling laws for language models.
    - Not relevant: papers that have experiments at different model scales (but do not explicitly fit a scaling law) or papers that mention scaling laws, but the scaling laws are not the central subject of the paper
 5. New methodological improvements about the model architecture improvments of large language models.
    - Relevant: papers that discuss state space models, recurrent neural networks, transformers, mixture of experts.
    - Not relevant: papers about theoretical analysis about shallow neural networks.
 6. Papers related with low rank properity of current language models.
    - Relevant: papers that study the rankness of weight, gradient, activation or other perspectives.
    - Not relevant: papers that discuss theoretical evidence about low rankness.

 In suggesting papers to your friend, remember that he enjoys papers on machine learning, and generative modeling in natural language processing.
 Your friend also likes learning about surprising empirical results in language models, as well as clever statistical tricks.
 He does not want to read papers that are about primarily applications of methods to specific domains.
